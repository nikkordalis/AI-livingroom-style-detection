{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e03a0ef",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f3872",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f078745",
   "metadata": {},
   "source": [
    "### Acces google drive or from local?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5186182d-e012-4888-a886-387f3a21e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "# from googleapiclient.discovery import build\n",
    "# from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# scope = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "# credentials = ServiceAccountCredentials.from_json_keyfile_name('service_account_key.json', scope)\n",
    "\n",
    "# # https://developers.google.com/drive/api/v3/quickstart/python\n",
    "# service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "# # Call the Drive v3 API\n",
    "# results = service.files().list(\n",
    "#     fields=\"*\",corpora = 'drive',supportsAllDrives = True, driveId = \"YOUR_DRIVE_ID\", includeItemsFromAllDrives = True).execute()\n",
    "# items = results.get('files', [])\n",
    "\n",
    "# if not items:\n",
    "#     print('No files found.')\n",
    "# else:\n",
    "#     print('Files:')\n",
    "#     for item in items:\n",
    "#         print(u'{0} ({1})'.format(item['name'], item['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e1448",
   "metadata": {},
   "source": [
    "### Create Dataframe file with two columns (complete path of image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b1381",
   "metadata": {},
   "source": [
    "Î™t would be better to do this directly from google drive otherwise we will have to download the images to the hard disk first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fa9bd",
   "metadata": {},
   "source": [
    "### View and check the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74bdc85",
   "metadata": {},
   "source": [
    "#### cleaning, dublicate etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270683ab",
   "metadata": {},
   "source": [
    "### Get label frequencies and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f374f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get label frequencies in descending order\n",
    "# label_freq = df['class'].apply(lambda s: str(s).split(',')).explode().value_counts().sort_values(ascending=False)\n",
    "\n",
    "# # Bar plot\n",
    "# style.use(\"fivethirtyeight\")\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "# plt.title(\"Label frequency\", fontsize=14)\n",
    "# plt.xlabel(\"\")\n",
    "# plt.xticks(fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de38106",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96644c0",
   "metadata": {},
   "source": [
    "### Working on a smaller dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Considering only 1/10th of the 50_000 images\n",
    "# reduction_factor = 10\n",
    "\n",
    "# # Choosing the random indices of small train set and small test set\n",
    "# idx_train =  np.random.choice(len(images_train), round(len(images_train)/reduction_factor))\n",
    "# idx_test =  np.random.choice(len(images_test), round(len(images_test)/reduction_factor))\n",
    "\n",
    "# # Collecting the two subsamples images_train_small and images_test_small from images_train and images_test\n",
    "# images_train_small = images_train[idx_train]\n",
    "# images_test_small = images_test[idx_test]\n",
    "# # and their corresponding labels\n",
    "# labels_train_small = labels_train[idx_train]\n",
    "# labels_test_small = labels_test[idx_test]\n",
    "\n",
    "# print(\"------------------ Before -----------------\")\n",
    "# print(images_train.shape, images_test.shape)\n",
    "\n",
    "# print(\"\")\n",
    "\n",
    "# print(\"--- After applying the reduction factor ---\")\n",
    "# print(images_train_small.shape, images_test_small.shape)\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"-\"*43)\n",
    "\n",
    "# unique, counts = np.unique(labels_train_small, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17365f1",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b91813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images into numpay array\n",
    "# Maybe already possible to define the size of the image here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d8b37",
   "metadata": {},
   "source": [
    "### Resize Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cb1b8",
   "metadata": {},
   "source": [
    "### Check how the images looks like (plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f0a70",
   "metadata": {},
   "source": [
    "**view a random image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662552d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def view_random_image(img_dir):\n",
    "#     # Folder\n",
    "#     fig = plt.figure(figsize=(15,5))\n",
    "#     for i in range(5):\n",
    "#         # Get a random image path\n",
    "#         random_image = random.sample(os.listdir(img_dir), 1)\n",
    "#         filename = img_dir+'/'+random_image[0]\n",
    "#         img = get_image(filename)\n",
    "#         img_class = df[df.images == random_image[0]]['class'].values[0]\n",
    "#         ax=fig.add_subplot(1,5,i+1)\n",
    "#         ax.set_title(img_class, fontsize=12)\n",
    "#         ax.axis(\"off\")\n",
    "#         plt.imshow(img)\n",
    "#     plt.show()\n",
    "\n",
    "# IMG_DIR = 'data/train_images'\n",
    "# view_random_image(IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427f9c8",
   "metadata": {},
   "source": [
    "###  Image preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359b686",
   "metadata": {},
   "source": [
    "#### One Hot  Encoding the labels and split the data and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be20fe",
   "metadata": {},
   "source": [
    "We create a new column labels which will be numerical. Now we have the first col images(name of image =string)\tthe second class (string) and the third\tlabels (numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_labels(classes, categories):   \n",
    "#     cate = np.asarray(categories)\n",
    "#     labels = []\n",
    "#     for x in classes:\n",
    "#         label = np.zeros(len(cate), dtype=np.int64)\n",
    "#         xs = x.split(',')\n",
    "#         for i in xs:\n",
    "#             ind = np.where(cate == i)[0][0]\n",
    "#             label[ind] = 1\n",
    "#         labels.append(label)\n",
    "#     return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['labels'] = pd.Series(get_labels(df['class'].values, categories))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09afd78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_dataset(dir, df, frac=0.8):\n",
    "#     X_train, y_train, X_valid, y_valid, X_test = [], [], [], [], []\n",
    "#     dfs = df.sample(frac=1, random_state=101)\n",
    "#     train = dfs[:int(frac*df.shape[0])]\n",
    "#     valid = dfs[int(frac*df.shape[0]):]\n",
    "#     train_arr = dir+'/'+train['images'].values\n",
    "#     valid_arr = dir+'/'+valid['images'].values\n",
    "#     X_train = [get_image(i, enc=True) for i in train_arr]\n",
    "#     X_valid = [get_image(i, enc=True) for i in valid_arr]\n",
    "#     y_train = train.labels.values\n",
    "#     y_valid = valid.labels.values\n",
    "#     return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c82bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different way to standardize \n",
    "\n",
    "# X_train = images_train / 255.\n",
    "# X_train_small = images_train_small / 255.\n",
    "# X_test = images_test / 255.\n",
    "# X_test_small = images_test_small / 255.\n",
    "\n",
    "# ### Encoding the labels\n",
    "\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# y_train = to_categorical(labels_train, 10)\n",
    "# y_train_small = to_categorical(labels_train_small, 10)\n",
    "# y_test = to_categorical(labels_test, 10)\n",
    "# y_test_small = to_categorical(labels_test_small, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ee725",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5727595",
   "metadata": {},
   "source": [
    "# Create TFRecord Dataset ????"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bed1daa4",
   "metadata": {},
   "source": [
    "The TFRecord format is a simple format for storing a sequence of binary records. Converting your data into TFRecord has many advantages, such as:\n",
    "\n",
    "More efficient storage: our origianl dataset is of 9GB Size, while TFRecords data takes just 300MB in total.\n",
    "Fast I/O: the TFRecord format can be read with parallel I/O operations, which is useful for TPUs or multiple hosts.\n",
    "Self-contained files: the TFRecord data can be read from a single source -- our original dataset originally stores data in two different formats (\"images\" and \"labels\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0a4a57",
   "metadata": {},
   "source": [
    "# Adapt pre Trained model like VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bc1ea",
   "metadata": {},
   "source": [
    "## Adapt the last dense and output layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36543b",
   "metadata": {},
   "source": [
    "**using the small training set to test first**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1eca99",
   "metadata": {},
   "source": [
    "### Functions for initialize and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ab119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_model():\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(16, (3, 3), activation = 'relu', padding = 'same', input_shape=(32, 32, 3)))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Conv2D(64, (2, 2), activation = 'relu', padding = 'same'))\n",
    "#     model.add(Dropout(0.3))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(100, activation = 'relu'))\n",
    "#     model.add(Dropout(0.4))\n",
    "#     model.add(Dense(10, activation = 'softmax'))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8023cc",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660de95e",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970c2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fa74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d8b95",
   "metadata": {},
   "source": [
    "##  Increase the size of your training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345d191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f2782",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94effa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b4e46b",
   "metadata": {},
   "source": [
    "# Check Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e818ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
    "# %tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ca28a",
   "metadata": {},
   "source": [
    "# Optimize Model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f948e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "# Auto optimization tool\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5814036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
